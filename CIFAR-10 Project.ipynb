{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06E-vqbxU6I0"
   },
   "source": [
    "# Adversarial Attacks#\n",
    "\n",
    "In this report Adversarial Attacks on Neural Networks are considered. \n",
    "\n",
    "- Initially three models are trained using common Convolutional Neural Network architectures. \n",
    "\n",
    "- Then using the resulting weights the Fast Gradient Sign Method is implemented.\n",
    "\n",
    "- The results are then compared for different levels of pertubation for all three architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9byGaFAITBdT"
   },
   "source": [
    "## Importing all the libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrxStl8xTBdW"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9itkLhsTBdZ"
   },
   "source": [
    "### Defining our Neural Net ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1ynNZXJdkQI"
   },
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LW8g_pOAc5lW"
   },
   "outputs": [],
   "source": [
    "# Neural Network Architecture \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.avgpool = nn.AvgPool2d(2, 2)\n",
    "        self.globalavgpool = nn.AvgPool2d(8, 8)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "        self.dropout10 = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(256, 10)\n",
    "\n",
    "# Forward function    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout10(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout10(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.globalavgpool(x)\n",
    "        x = self.dropout50(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MC7E7_z1rD8V"
   },
   "source": [
    "Above is a custom architecture the main feautures of this are:\n",
    "\n",
    "- Three stacked convolutional kernals. Stacked convolutional kernals are very useful and serve two main purposes. Dicounting the first layer if we wish to increase the receptive field of a kernal we should stack two layers on top of eachother. Also it adds non-linearity to the model making it more powerful. \n",
    "\n",
    "- Pooling Layers it uses three time average,max and global average pooling. \n",
    "\n",
    "- Uses Relu activation function  this is the default activation function and very fast to compute. It does have some issues but they are mostly addressed by its many variants such as leaky Relu and PRelu\n",
    "\n",
    "- Before the last layer there is a dropout layer to prevent overfitting then the input in flattenend (requires 1D input) so it can be ready for the fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paeK9-tTddtv"
   },
   "source": [
    "# LeNet-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4D1NJvITBda"
   },
   "outputs": [],
   "source": [
    "# Neural Net architecture for lenet-5\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "# Forward function \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpKRHHDlrPEP"
   },
   "source": [
    "Above is the architecture of the lenet-5 Neural Net. It is very simple and consists of only a few hidden layers. It is very famous and was used by the banks to check the digits on hand written cheques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqyOxCQydXD8"
   },
   "source": [
    "# ResNet#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKJuyM0bdI9j"
   },
   "outputs": [],
   "source": [
    "# Neural Net architecture for ResNet\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "McCx0I7LrSxe"
   },
   "source": [
    "This is the ResNet architecture. It is somewhat more complicated then the preceding Networks. Also it is not a simple FeedFoward Network, where layers are only connected to preceeding layers. We have skip layers now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZba06glTBdd"
   },
   "source": [
    "## Define FGSM function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6fMf332KLgH"
   },
   "source": [
    "An Adversarial Attack is an attempt to cause a classifier to misclassify an image that it is presented with. Whilst Neural Networks are incredibly powerful and have unrivalled classification rates it is remarkably simple to fool them to misclassify the image they are shown.Part of the problem with Neural Nets is there interpretability.  Humans can perceive things in a way that Neural Nets cannot, but do not think humans cannot be tricked there are numerous illusions that many will be familiar with.  This is a problem if we consider the modern world and AI for example self-driving cars. \n",
    "\n",
    "There are several cases or types of attack that can be considered. For instance are we interested in the output class of the image or do we simply require that the image is misclassified ?\n",
    "\n",
    "Do we have information such as the architecture and weights of the model we wish to fool, or do we just know the output and input classes?\n",
    "\n",
    "The approach we pursue will depend on the answers to the above and are summarised below.\n",
    "Targeted (Here we want to fool the classifier to a specific class) / Untargeted (We do not care about the output class just that it is different from the ground truth) / Black box (Nothing about the model weights or its architecture is known only the corresponding inputs and outputs) / White box (All the details of the model are known) \n",
    "\n",
    "A single channel 28x28 image is made up of 784 pixels each pixel is represented by its intensity 0-255. \n",
    "We wish to fool a classifier subject to the requirement that any alteration that we make to the image be minimal. A norm that penalises changes is needed. Some commonly used are the p norm or l norm. \n",
    "The perturbation applied should be imperceptible, that is a human looking at the image should not be able to see the input has been tampered with.\n",
    "A successful attack is one which fools the classifier without being noticed by the user. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wdlW53-rYCQ"
   },
   "source": [
    "Here is the fgsm function from the pytorch tutorial. \n",
    "\n",
    "The function takes three arguments the base image epsilon the amount of pertubation and the data_gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPg2dRPMTBde"
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5GiEiaJTBdh"
   },
   "source": [
    "## Importing Data and Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TK8OvYzlsE3i"
   },
   "source": [
    "Torchvision is used to import the data and is used so that we do not need to worry about the preprocessing of the data. It is a very useful tool especially if you are interested in quickly validating your model using a well known dataset.  \n",
    "\n",
    "Data Augmentation \n",
    "\n",
    "- To train a deep Neural Net a large amount of labelled training data is required in the literature around 100K is an often referenced number. This sometimes is often not possible so data augamentation can be used to artificially increase the size of the training data. This is done by applying transformations, rotations and changing the contrast of images. It can increase the size of the data set by around 50x and makes the network invariant to small changes. It regularizes the model and stops overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XUcEjFWwnH8"
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pic_size = 32\n",
    "aug = iaa.Sequential([\n",
    "        iaa.Affine(\n",
    "        scale=(0.8, 1.2), \n",
    "        rotate=(-5, 5), \n",
    "        order=[0],),\n",
    "        iaa.PadToFixedSize(pic_size, pic_size),\n",
    "        iaa.CropToFixedSize(pic_size, pic_size),\n",
    "        iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=1.0)),\n",
    "        iaa.Sometimes(0.5, iaa.SaltAndPepper(0.06, per_channel=True)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_OIU2E2wnVq"
   },
   "outputs": [],
   "source": [
    "class CIFAR10_iaa(datasets.CIFAR10):\n",
    "    def __getitem__(self, idx):\n",
    "        pil, target = super().__getitem__(idx)\n",
    "        img = aug(image=np.array(pil)) / 255\n",
    "        return img.transpose((2, 0, 1)), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WPKLx5ioTBdi",
    "outputId": "a2ae1675-e8ea-4752-dc13-20aacb11cbd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Enter the training and testing batch size \n",
    "train_batch_size = 100\n",
    "test_batch_size = 1\n",
    "\n",
    "# To use autgrad we must convert to tensor\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),])\n",
    "\n",
    "# Import CIFAR10 and specify batch size \n",
    "\n",
    "# Training data\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Testing data\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Specify the classes in the dataset \n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiUDjav-TBdm"
   },
   "source": [
    "## Training of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEKwo-zbTBdm"
   },
   "source": [
    "### Init Net and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnUi83FXTBdn"
   },
   "outputs": [],
   "source": [
    "# Use the GPU if available to speed up training \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:2\")\n",
    "net = Net().train().to(device)\n",
    "lenet = LeNet().train().to(device)\n",
    "resnet = ResNet18().train().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dW01rjiSW-EH"
   },
   "source": [
    "###Summary of the architecture for all three networks###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "LbBhX_FpchHx",
    "outputId": "1e327023-331e-45ec-ec3a-154c975eaf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "            Conv2d-2           [-1, 64, 32, 32]          36,928\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "           Dropout-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "            Conv2d-6          [-1, 128, 16, 16]         147,584\n",
      "         AvgPool2d-7            [-1, 128, 8, 8]               0\n",
      "           Dropout-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
      "           Conv2d-10            [-1, 256, 8, 8]         590,080\n",
      "        AvgPool2d-11            [-1, 256, 1, 1]               0\n",
      "          Dropout-12            [-1, 256, 1, 1]               0\n",
      "           Linear-13                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,147,978\n",
      "Trainable params: 1,147,978\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.13\n",
      "Params size (MB): 4.38\n",
      "Estimated Total Size (MB): 6.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "ZBBJHHJLcu_0",
    "outputId": "5365a00a-e29a-47e7-eaa0-2bbafa36d888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
      "            Linear-3                  [-1, 120]          48,120\n",
      "            Linear-4                   [-1, 84]          10,164\n",
      "            Linear-5                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(lenet,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yRnFy7x6c3b5",
    "outputId": "b9f73200-faae-4ae6-8798-0c03a719a7ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CK1y3JpdTBdq"
   },
   "source": [
    "### Selecting the loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cO_1hCNcMsPF"
   },
   "source": [
    "Selecting the optimiser is very important on large data sets using gradient descent or batch gradient descent is not feasible so we must select another. The default is Stochastic Gradient Descent here Adam is used there are others available and can be experimented with such as RMSPROP, gradient descent with momentum, nestorov gradient descent, nadam and ADAgrad.\n",
    "\n",
    "Adam is an adaptive variant of Stochastic Gradient Descent. It utilises different learning rates for different parameters.\n",
    "\n",
    "Also we can see cross entropy loss is used. Cross entropy measures and penalizes our model depending on whether its prediction matches the base truth and the strength of this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWWa3tO_TBdr"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_net = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer_lenet = optim.Adam(lenet.parameters(), lr=0.001)\n",
    "optimizer_resnet = optim.Adam(resnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdjms6miTBdv"
   },
   "source": [
    "### Training and saving the weights of the each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "colab_type": "code",
    "id": "3GmLoCeKTBdw",
    "outputId": "0d2429ac-d4a3-450a-f631-755e0ed0ad6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10000] loss: 1.9794\n",
      "[1, 20000] loss: 1.9483\n",
      "[1, 30000] loss: 1.8016\n",
      "[1, 40000] loss: 1.6917\n",
      "[1, 50000] loss: 1.7501\n",
      "[2, 10000] loss: 1.3842\n",
      "[2, 20000] loss: 1.6629\n",
      "[2, 30000] loss: 1.5884\n",
      "[2, 40000] loss: 1.3742\n",
      "[2, 50000] loss: 1.4393\n",
      "[3, 10000] loss: 1.4833\n",
      "[3, 20000] loss: 1.3559\n",
      "[3, 30000] loss: 1.1429\n",
      "[3, 40000] loss: 1.1664\n",
      "[3, 50000] loss: 1.2280\n",
      "[4, 10000] loss: 1.0342\n",
      "[4, 20000] loss: 1.2945\n",
      "[4, 30000] loss: 1.1462\n",
      "[4, 40000] loss: 1.0342\n",
      "[4, 50000] loss: 0.8614\n",
      "[5, 10000] loss: 1.0971\n",
      "[5, 20000] loss: 1.2550\n",
      "[5, 30000] loss: 0.8473\n",
      "[5, 40000] loss: 1.0403\n",
      "[5, 50000] loss: 1.2601\n",
      "[6, 10000] loss: 0.7751\n",
      "[6, 20000] loss: 0.9899\n",
      "[6, 30000] loss: 0.9269\n",
      "[6, 40000] loss: 0.9521\n",
      "[6, 50000] loss: 1.2919\n",
      "[7, 10000] loss: 0.9530\n",
      "[7, 20000] loss: 0.9641\n",
      "[7, 30000] loss: 0.8921\n",
      "[7, 40000] loss: 0.6856\n",
      "[7, 50000] loss: 0.7589\n",
      "[8, 10000] loss: 0.7285\n",
      "[8, 20000] loss: 0.7976\n",
      "[8, 30000] loss: 0.6965\n",
      "[8, 40000] loss: 0.7635\n",
      "[8, 50000] loss: 0.8023\n",
      "[9, 10000] loss: 0.9185\n",
      "[9, 20000] loss: 0.6368\n",
      "[9, 30000] loss: 0.7355\n",
      "[9, 40000] loss: 0.6758\n",
      "[9, 50000] loss: 0.6488\n",
      "[10, 10000] loss: 0.7441\n",
      "[10, 20000] loss: 0.5992\n",
      "[10, 30000] loss: 0.7202\n",
      "[10, 40000] loss: 0.7651\n",
      "[10, 50000] loss: 0.6698\n",
      "Finished Training\n",
      "CPU times: user 3min 13s, sys: 1min 37s, total: 4min 50s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer_net.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_net.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), './cifar10_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "colab_type": "code",
    "id": "KhGjT-WPeXX5",
    "outputId": "9088cc40-7b1b-4267-eec1-55490988abf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10000] loss: 1.9930\n",
      "[1, 20000] loss: 1.8100\n",
      "[1, 30000] loss: 1.7825\n",
      "[1, 40000] loss: 1.6510\n",
      "[1, 50000] loss: 1.6233\n",
      "[2, 10000] loss: 1.5035\n",
      "[2, 20000] loss: 1.4824\n",
      "[2, 30000] loss: 1.4886\n",
      "[2, 40000] loss: 1.3122\n",
      "[2, 50000] loss: 1.2867\n",
      "[3, 10000] loss: 1.4510\n",
      "[3, 20000] loss: 1.2409\n",
      "[3, 30000] loss: 1.3712\n",
      "[3, 40000] loss: 1.4429\n",
      "[3, 50000] loss: 1.4198\n",
      "[4, 10000] loss: 1.4119\n",
      "[4, 20000] loss: 1.5028\n",
      "[4, 30000] loss: 1.2956\n",
      "[4, 40000] loss: 1.3181\n",
      "[4, 50000] loss: 1.3297\n",
      "[5, 10000] loss: 1.3137\n",
      "[5, 20000] loss: 1.0425\n",
      "[5, 30000] loss: 1.2288\n",
      "[5, 40000] loss: 1.1652\n",
      "[5, 50000] loss: 1.4083\n",
      "[6, 10000] loss: 1.1667\n",
      "[6, 20000] loss: 1.0497\n",
      "[6, 30000] loss: 1.2147\n",
      "[6, 40000] loss: 1.3319\n",
      "[6, 50000] loss: 1.2546\n",
      "[7, 10000] loss: 1.1850\n",
      "[7, 20000] loss: 1.1473\n",
      "[7, 30000] loss: 1.0790\n",
      "[7, 40000] loss: 1.0777\n",
      "[7, 50000] loss: 1.2354\n",
      "[8, 10000] loss: 1.3227\n",
      "[8, 20000] loss: 1.0755\n",
      "[8, 30000] loss: 1.1222\n",
      "[8, 40000] loss: 1.0981\n",
      "[8, 50000] loss: 1.1270\n",
      "[9, 10000] loss: 1.0792\n",
      "[9, 20000] loss: 1.1112\n",
      "[9, 30000] loss: 1.0896\n",
      "[9, 40000] loss: 1.0656\n",
      "[9, 50000] loss: 1.2149\n",
      "[10, 10000] loss: 0.9684\n",
      "[10, 20000] loss: 0.9712\n",
      "[10, 30000] loss: 1.2798\n",
      "[10, 40000] loss: 1.0272\n",
      "[10, 50000] loss: 0.9720\n",
      "Finished Training\n",
      "CPU times: user 58.9 s, sys: 5.7 s, total: 1min 4s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer_lenet.zero_grad()\n",
    "        \n",
    "        outputs = lenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_lenet.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(lenet.state_dict(), './cifar10_lenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "colab_type": "code",
    "id": "r2qS-QkxeXJ9",
    "outputId": "2e55c08c-af86-4c7d-bd3f-e7479618826c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10000] loss: 1.5089\n",
      "[1, 20000] loss: 1.3168\n",
      "[1, 30000] loss: 1.0204\n",
      "[1, 40000] loss: 1.1253\n",
      "[1, 50000] loss: 0.9807\n",
      "[2, 10000] loss: 0.9102\n",
      "[2, 20000] loss: 0.9501\n",
      "[2, 30000] loss: 0.7660\n",
      "[2, 40000] loss: 0.7343\n",
      "[2, 50000] loss: 0.7737\n",
      "[3, 10000] loss: 0.6693\n",
      "[3, 20000] loss: 0.4889\n",
      "[3, 30000] loss: 0.6973\n",
      "[3, 40000] loss: 0.4404\n",
      "[3, 50000] loss: 0.4643\n",
      "[4, 10000] loss: 0.5019\n",
      "[4, 20000] loss: 0.6043\n",
      "[4, 30000] loss: 0.5739\n",
      "[4, 40000] loss: 0.4379\n",
      "[4, 50000] loss: 0.3641\n",
      "[5, 10000] loss: 0.6298\n",
      "[5, 20000] loss: 0.3980\n",
      "[5, 30000] loss: 0.3773\n",
      "[5, 40000] loss: 0.5306\n",
      "[5, 50000] loss: 0.2381\n",
      "[6, 10000] loss: 0.3737\n",
      "[6, 20000] loss: 0.2025\n",
      "[6, 30000] loss: 0.3339\n",
      "[6, 40000] loss: 0.3689\n",
      "[6, 50000] loss: 0.4358\n",
      "[7, 10000] loss: 0.1961\n",
      "[7, 20000] loss: 0.1781\n",
      "[7, 30000] loss: 0.2591\n",
      "[7, 40000] loss: 0.1740\n",
      "[7, 50000] loss: 0.2989\n",
      "[8, 10000] loss: 0.1120\n",
      "[8, 20000] loss: 0.1174\n",
      "[8, 30000] loss: 0.2890\n",
      "[8, 40000] loss: 0.1232\n",
      "[8, 50000] loss: 0.3048\n",
      "[9, 10000] loss: 0.0835\n",
      "[9, 20000] loss: 0.0962\n",
      "[9, 30000] loss: 0.2058\n",
      "[9, 40000] loss: 0.1905\n",
      "[9, 50000] loss: 0.2863\n",
      "[10, 10000] loss: 0.0711\n",
      "[10, 20000] loss: 0.0894\n",
      "[10, 30000] loss: 0.1055\n",
      "[10, 40000] loss: 0.0698\n",
      "[10, 50000] loss: 0.2029\n",
      "Finished Training\n",
      "CPU times: user 17min 57s, sys: 11min 4s, total: 29min 2s\n",
      "Wall time: 29min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer_resnet.zero_grad()\n",
    "        \n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_resnet.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*train_batch_size, loss.item()))\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(resnet.state_dict(), './cifar10_resnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efNOMWi6TBdy"
   },
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aM_4kItLTBdz",
    "outputId": "0b8062c9-70e7-42f0-8a69-a8757d33b64d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the weights of the pretrained models\n",
    "net.load_state_dict(torch.load('./cifar10_net.pth', map_location='cpu'))\n",
    "lenet.load_state_dict(torch.load('./cifar10_lenet.pth', map_location='cpu'))\n",
    "resnet.load_state_dict(torch.load('./cifar10_resnet.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQcq1buFTBd3"
   },
   "source": [
    "### Evaluate the mode & fix the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7EBNe3gTBd3"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0w3kS_6pfzfm"
   },
   "outputs": [],
   "source": [
    "lenet.eval()\n",
    "for p in lenet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqDus0GsfzQh"
   },
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "for p in resnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZ3JlHBeTBd6"
   },
   "source": [
    "### Accuracy of the Net model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "KRV81qDyTBd6",
    "outputId": "dd2ba748-b569-4115-f06b-6d9ccf4e8b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Net network on the 10000 test images: 77 %\n",
      "Net Network: Accuracy of plane : 78 %\n",
      "Net Network: Accuracy of   car : 92 %\n",
      "Net Network: Accuracy of  bird : 72 %\n",
      "Net Network: Accuracy of   cat : 55 %\n",
      "Net Network: Accuracy of  deer : 73 %\n",
      "Net Network: Accuracy of   dog : 59 %\n",
      "Net Network: Accuracy of  frog : 83 %\n",
      "Net Network: Accuracy of horse : 81 %\n",
      "Net Network: Accuracy of  ship : 89 %\n",
      "Net Network: Accuracy of truck : 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "print('Accuracy of the Net network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    " \n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(test_batch_size):\n",
    "            label = labels[i]\n",
    "#           class_correct[label] += c[i].item()\n",
    "            class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    " \n",
    " \n",
    "for i in range(10):\n",
    "    print('Net Network: Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6-DoCK9egJW"
   },
   "source": [
    "### Accuracy of the LeNet-5 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "RwwDrDocf_PZ",
    "outputId": "7ea072d5-c552-49f3-fdc5-d72618039230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the LeNet network on the 10000 test images: 61 %\n",
      "LeNet Network: Accuracy of plane : 70 %\n",
      "LeNet Network: Accuracy of   car : 72 %\n",
      "LeNet Network: Accuracy of  bird : 52 %\n",
      "LeNet Network: Accuracy of   cat : 26 %\n",
      "LeNet Network: Accuracy of  deer : 49 %\n",
      "LeNet Network: Accuracy of   dog : 59 %\n",
      "LeNet Network: Accuracy of  frog : 72 %\n",
      "LeNet Network: Accuracy of horse : 67 %\n",
      "LeNet Network: Accuracy of  ship : 71 %\n",
      "LeNet Network: Accuracy of truck : 72 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = lenet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "print('Accuracy of the LeNet network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    " \n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = lenet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(test_batch_size):\n",
    "            label = labels[i]\n",
    "#           class_correct[label] += c[i].item()\n",
    "            class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    " \n",
    " \n",
    "for i in range(10):\n",
    "    print('LeNet Network: Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTah70K7ekoo"
   },
   "source": [
    "### Accuracy of the ResNet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "rghet3eVf--h",
    "outputId": "330182e9-516c-499f-852a-e75a1be34cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ResNet network on the 10000 test images: 83 %\n",
      "ResNet Network: Accuracy of plane : 86 %\n",
      "ResNet Network: Accuracy of   car : 91 %\n",
      "ResNet Network: Accuracy of  bird : 78 %\n",
      "ResNet Network: Accuracy of   cat : 74 %\n",
      "ResNet Network: Accuracy of  deer : 78 %\n",
      "ResNet Network: Accuracy of   dog : 71 %\n",
      "ResNet Network: Accuracy of  frog : 82 %\n",
      "ResNet Network: Accuracy of horse : 87 %\n",
      "ResNet Network: Accuracy of  ship : 89 %\n",
      "ResNet Network: Accuracy of truck : 93 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "print('Accuracy of the ResNet network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    " \n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(test_batch_size):\n",
    "            label = labels[i]\n",
    "#           class_correct[label] += c[i].item()\n",
    "            class_correct[label] += c.item()\n",
    "            class_total[label] += 1\n",
    " \n",
    " \n",
    "for i in range(10):\n",
    "    print('ResNet Network: Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj7m2maSVYRn"
   },
   "source": [
    "Interestingly all three networks they had simarlaly poor performance on the bird,cat,deer and dog classes. It is only possible to speculate why this may be as with only this information it cannot be known for certain ,as it appears in all three there it is likely some underlying cause is responsible. A possible approach would be to check the correlation between these classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBEgtoCGTBd9"
   },
   "source": [
    "### Adversarial Attack using FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5RCESxBTBd9"
   },
   "outputs": [],
   "source": [
    "# Here we define the function that tests our model\n",
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbtCXyKfgRC5"
   },
   "source": [
    "### Here we run the attacks and evaluate the accuracy for different values of epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "LSRDapUsTBeB",
    "outputId": "75eca716-ee35-4c90-97f7-e5713a9db662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 8264 / 10000 = 0.8264\n",
      "Epsilon: 0.01\tTest Accuracy = 3861 / 10000 = 0.3861\n",
      "Epsilon: 0.02\tTest Accuracy = 1898 / 10000 = 0.1898\n",
      "Epsilon: 0.03\tTest Accuracy = 1169 / 10000 = 0.1169\n",
      "Epsilon: 0.04\tTest Accuracy = 898 / 10000 = 0.0898\n",
      "Epsilon: 0.05\tTest Accuracy = 782 / 10000 = 0.0782\n",
      "Epsilon: 0.06\tTest Accuracy = 738 / 10000 = 0.0738\n",
      "Epsilon: 0.07\tTest Accuracy = 710 / 10000 = 0.071\n",
      "Epsilon: 0.08\tTest Accuracy = 682 / 10000 = 0.0682\n",
      "Epsilon: 0.09\tTest Accuracy = 681 / 10000 = 0.0681\n",
      "Epsilon: 0.1\tTest Accuracy = 697 / 10000 = 0.0697\n",
      "CPU times: user 6min 3s, sys: 30 s, total: 6min 33s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies_net = []\n",
    "examples_net = []\n",
    "epsilons_net = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
    "# Run test for each epsilon\n",
    "# testloader batchsize should be 1\n",
    "for eps in epsilons_net:\n",
    "    acc, ex = test(net, device, testloader, eps)\n",
    "    accuracies_net.append(acc)\n",
    "    examples_net.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "TvFSugaJi5IY",
    "outputId": "b73e838d-7f9c-46c2-9e6c-984d6689970a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 8264 / 10000 = 0.8264\n",
      "Epsilon: 0.02\tTest Accuracy = 1898 / 10000 = 0.1898\n",
      "Epsilon: 0.04\tTest Accuracy = 898 / 10000 = 0.0898\n",
      "Epsilon: 0.06\tTest Accuracy = 738 / 10000 = 0.0738\n",
      "Epsilon: 0.08\tTest Accuracy = 682 / 10000 = 0.0682\n",
      "Epsilon: 0.1\tTest Accuracy = 697 / 10000 = 0.0697\n",
      "Epsilon: 0.12\tTest Accuracy = 712 / 10000 = 0.0712\n",
      "Epsilon: 0.14\tTest Accuracy = 722 / 10000 = 0.0722\n",
      "Epsilon: 0.16\tTest Accuracy = 738 / 10000 = 0.0738\n",
      "Epsilon: 0.18\tTest Accuracy = 755 / 10000 = 0.0755\n",
      "Epsilon: 0.2\tTest Accuracy = 752 / 10000 = 0.0752\n",
      "CPU times: user 6min 6s, sys: 29.9 s, total: 6min 36s\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies_net2 = []\n",
    "examples_net2 = []\n",
    "epsilons_net2 = [0, .02, .04, .06, .08, .1, .12,.14,.16,.18,.2]\n",
    "\n",
    "# Run test for each epsilon\n",
    "# testloader batchsize should be 1\n",
    "for eps in epsilons_net2:\n",
    "    acc, ex = test(net, device, testloader, eps)\n",
    "    accuracies_net2.append(acc)\n",
    "    examples_net2.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "roIpHiVHkjt2",
    "outputId": "d1e266bd-adc2-41f1-fd4e-f2e1ad882247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 8264 / 10000 = 0.8264\n",
      "Epsilon: 0.05\tTest Accuracy = 782 / 10000 = 0.0782\n",
      "Epsilon: 0.1\tTest Accuracy = 697 / 10000 = 0.0697\n",
      "Epsilon: 0.15\tTest Accuracy = 714 / 10000 = 0.0714\n",
      "Epsilon: 0.2\tTest Accuracy = 752 / 10000 = 0.0752\n",
      "Epsilon: 0.25\tTest Accuracy = 758 / 10000 = 0.0758\n",
      "Epsilon: 0.3\tTest Accuracy = 801 / 10000 = 0.0801\n",
      "Epsilon: 0.35\tTest Accuracy = 818 / 10000 = 0.0818\n",
      "Epsilon: 0.4\tTest Accuracy = 871 / 10000 = 0.0871\n",
      "Epsilon: 0.45\tTest Accuracy = 900 / 10000 = 0.09\n",
      "Epsilon: 0.5\tTest Accuracy = 926 / 10000 = 0.0926\n",
      "CPU times: user 6min 8s, sys: 29.4 s, total: 6min 37s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies_net3 = []\n",
    "examples_net3 = []\n",
    "epsilons_net3 = [0, .05, .1, .15, .2, .25, .3,.35,.4,.45,.5]\n",
    "\n",
    "# Run test for each epsilon\n",
    "# testloader batchsize should be 1\n",
    "for eps in epsilons_net3:\n",
    "    acc, ex = test(net, device, testloader, eps)\n",
    "    accuracies_net3.append(acc)\n",
    "    examples_net3.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "GFh6g91Wh-IB",
    "outputId": "805ce372-79de-4d42-c8a3-481e5449aca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 6161 / 10000 = 0.6161\n",
      "Epsilon: 0.01\tTest Accuracy = 2570 / 10000 = 0.257\n",
      "Epsilon: 0.02\tTest Accuracy = 1049 / 10000 = 0.1049\n",
      "Epsilon: 0.03\tTest Accuracy = 444 / 10000 = 0.0444\n",
      "Epsilon: 0.04\tTest Accuracy = 211 / 10000 = 0.0211\n",
      "Epsilon: 0.05\tTest Accuracy = 110 / 10000 = 0.011\n",
      "Epsilon: 0.06\tTest Accuracy = 82 / 10000 = 0.0082\n",
      "Epsilon: 0.07\tTest Accuracy = 69 / 10000 = 0.0069\n",
      "Epsilon: 0.08\tTest Accuracy = 60 / 10000 = 0.006\n",
      "Epsilon: 0.09\tTest Accuracy = 57 / 10000 = 0.0057\n",
      "Epsilon: 0.1\tTest Accuracy = 50 / 10000 = 0.005\n"
     ]
    }
   ],
   "source": [
    "accuracies_lenet = []\n",
    "examples_lenet = []\n",
    "epsilons_lenet = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
    "\n",
    "# Run test for each epsilon\n",
    "# testloader batchsize should be 1\n",
    "for eps in epsilons_lenet:\n",
    "    acc, ex = test(lenet, device, testloader, eps)\n",
    "    accuracies_lenet.append(acc)\n",
    "    examples_lenet.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "fvOXzSQuh95_",
    "outputId": "b03be557-715f-499f-8aec-9e1bf372b62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 8320 / 10000 = 0.832\n",
      "Epsilon: 0.01\tTest Accuracy = 1449 / 10000 = 0.1449\n",
      "Epsilon: 0.02\tTest Accuracy = 433 / 10000 = 0.0433\n",
      "Epsilon: 0.03\tTest Accuracy = 235 / 10000 = 0.0235\n",
      "Epsilon: 0.04\tTest Accuracy = 176 / 10000 = 0.0176\n",
      "Epsilon: 0.05\tTest Accuracy = 155 / 10000 = 0.0155\n",
      "Epsilon: 0.06\tTest Accuracy = 132 / 10000 = 0.0132\n",
      "Epsilon: 0.07\tTest Accuracy = 132 / 10000 = 0.0132\n",
      "Epsilon: 0.08\tTest Accuracy = 131 / 10000 = 0.0131\n",
      "Epsilon: 0.09\tTest Accuracy = 141 / 10000 = 0.0141\n",
      "Epsilon: 0.1\tTest Accuracy = 144 / 10000 = 0.0144\n"
     ]
    }
   ],
   "source": [
    "accuracies_resnet = []\n",
    "examples_resnet = []\n",
    "epsilons_resnet = [0, .01, .02, .03, .04, .05, .06,.07,.08,.09,.1]\n",
    "\n",
    "# Run test for each epsilon\n",
    "# testloader batchsize should be 1\n",
    "for eps in epsilons_resnet:\n",
    "    acc, ex = test(resnet, device, testloader, eps)\n",
    "    accuracies_resnet.append(acc)\n",
    "    examples_resnet.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bati9vmognj5"
   },
   "source": [
    "### Plots showing the Accuracy vs Epsilon Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_SqPHEFE6USM",
    "outputId": "684fcb39-839a-4233-e78b-1a948c1c5f6b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neTgozczycFCameXx/wEB5LQ1bhEx7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIf7X4bKcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njagejZotAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of Accuracy vs Epsilon with 0.01 step size \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_net, accuracies_net, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .1, step=0.01))\n",
    "plt.title(\"0.01 step\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Plot of Accuracy vs Epsilon with 0.02 step size \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_net2, accuracies_net2, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .2, step=0.02))\n",
    "plt.title(\"0.02 step\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Plot of Accuracy vs Epsilon with 0.05 step size \n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_net3, accuracies_net3, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .5, step=0.05))\n",
    "plt.title(\"0.05 step\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7mKvE83NbZC"
   },
   "source": [
    "Changing the epsilon value beyond a certain point does not seem to further deteriorate the rate of misclassification in this case around 0.05. This pertubation is small especially compared with the epsillon required in a single channel greyscale image like FashionMNIST. Models that classify three channel images are less robust to adversarial attacks it seems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "wY0kMDLduWU_",
    "outputId": "25c58582-cc42-4374-aee2-de4fa44fa7ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f47b62b40f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAWuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using matplotlib to plot the degradation in accuracy for three different architectures \n",
    "plt.plot( epsilons_net, accuracies_net, color='skyblue', linewidth=2, label=\"Net Architecture\")\n",
    "plt.plot( epsilons_lenet, accuracies_lenet, color='olive', linewidth=2, label=\"LeNet Architecture\")\n",
    "plt.plot( epsilons_resnet, accuracies_resnet, color='red',linewidth=2, label=\"ResNet Architecture\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhWZy3NVN5oP"
   },
   "source": [
    "The three architectures and there response to adversarial attacks. \n",
    "\n",
    "The best performing architecture seems to be the least robust. Why this could be? It could be overfitting. \n",
    "\n",
    "LeNet performed poorly on the training set it is not surprising that a larger pertubation is required to fool this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zq7-RobVQEm6"
   },
   "source": [
    "Conclusion and summary \n",
    "\n",
    "Three Neural Networks were trained then attacked using the fast gradient sign method their robustness varied.\n",
    "\n",
    "To protect our model we could train it using some adversarial examples, this however would reduce the accuracy of our training data i.e it would be a worse classifier and for that reason it would be harder to attack.  There are other techniques that could be used however there is no simple way to combat adversarial examples what is required is an adaptive method which does not exist.\n",
    "\n",
    "Further Reading \n",
    "\n",
    "- Adversarial training can result in regularization even further regularization than dropout. \n",
    "\n",
    "- Models that are easy to optimize are easy to perturb.\n",
    "\n",
    "- Ensembles are not resistant to adversarial examples.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Copy of Copy of cifar10_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
